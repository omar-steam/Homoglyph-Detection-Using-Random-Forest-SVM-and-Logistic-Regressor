{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install the confusables package (parses Unicode confusable characters)\n",
        "!pip install confusables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyEw30c-VMtx",
        "outputId": "4e6e122c-30b1-414e-fb65-9d8ebc13f78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting confusables\n",
            "  Downloading confusables-1.2.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Downloading confusables-1.2.0-py3-none-any.whl (268 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.5/268.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: confusables\n",
            "Successfully installed confusables-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from confusables import confusable_characters\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "tNwWvTyAVK19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example word list (expand with dictionary, domains, etc.)\n",
        "words = [\"password\", \"secure\", \"exchange\", \"login\", \"facebook\", \"microsoft\", \"apple\", \"orange\"]\n",
        "\n",
        "data, labels = [], []\n",
        "\n",
        "for w in words:\n",
        "    # Clean sample\n",
        "    data.append(w)\n",
        "    labels.append(0)\n",
        "\n",
        "    # Homoglyph substitution\n",
        "    noisy = list(w)\n",
        "    replaced = False\n",
        "    for i, ch in enumerate(noisy):\n",
        "        homoglyphs = confusable_characters(ch)\n",
        "        if homoglyphs and random.random() < 0.5:  # 50% chance to replace\n",
        "            noisy[i] = random.choice(homoglyphs)\n",
        "            replaced = True\n",
        "\n",
        "    noisy_word = \"\".join(noisy)\n",
        "    if replaced and noisy_word != w:\n",
        "        data.append(noisy_word)\n",
        "        labels.append(1)\n",
        "\n",
        "print(\"Sample dataset:\")\n",
        "for d, l in zip(data[:10], labels[:10]):\n",
        "    print(d, \"->\", l)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THecheciVZgh",
        "outputId": "71afded7-eb73-4737-a2c3-9bfaf1dc5cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample dataset:\n",
            "password -> 0\n",
            "pÃ£á¹¦swğ‘£ˆá¹›ê““ -> 1\n",
            "secure -> 0\n",
            "ÅšÃªcÎ¥re -> 1\n",
            "exchange -> 0\n",
            "ï½…xá¸ˆá¸©ğ°Å„ge -> 1\n",
            "login -> 0\n",
            "loğ“–in -> 1\n",
            "facebook -> 0\n",
            "ê˜acğ‘’ê“á» Å‘ğ™º -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use character-level n-grams\n",
        "vectorizer = CountVectorizer(analyzer=\"char\", ngram_range=(1,2))\n",
        "X = vectorizer.fit_transform(data)\n",
        "y = np.array(labels)\n",
        "\n",
        "print(\"Feature matrix shape:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4e2_BzsVdy0",
        "outputId": "0a33e4f5-0231-4a10-9d45-5f4afc6cfb00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix shape: (16, 133)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train size:\", X_train.shape[0])\n",
        "print(\"Test size:\", X_test.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNNIIKrvVhwc",
        "outputId": "c40fee7f-aaca-4877-d618-177dfb912d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 11\n",
            "Test size: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, C=1.0),\n",
        "    \"SVM\": SVC(kernel=\"linear\", probability=True),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=cv)\n",
        "    print(f\"{name} CV Accuracy: {scores.mean():.3f} Â± {scores.std():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSHgpwJfVj9I",
        "outputId": "6b0775a2-dd74-4336-c04a-5e13d6c7d757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression CV Accuracy: 0.367 Â± 0.194\n",
            "SVM CV Accuracy: 0.367 Â± 0.194\n",
            "Random Forest CV Accuracy: 0.433 Â± 0.226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"=\"*40)\n",
        "    print(f\"{name} Test Performance\")\n",
        "    print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROl-byQ5VoMV",
        "outputId": "0f7de764-8fb6-43e5-bc9d-930de2817f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "Logistic Regression Test Performance\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.67      0.80         3\n",
            "           1       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.83      0.83      0.80         5\n",
            "weighted avg       0.87      0.80      0.80         5\n",
            "\n",
            "========================================\n",
            "SVM Test Performance\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.67      0.67         3\n",
            "           1       0.50      0.50      0.50         2\n",
            "\n",
            "    accuracy                           0.60         5\n",
            "   macro avg       0.58      0.58      0.58         5\n",
            "weighted avg       0.60      0.60      0.60         5\n",
            "\n",
            "========================================\n",
            "Random Forest Test Performance\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.67      0.80         3\n",
            "           1       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.80         5\n",
            "   macro avg       0.83      0.83      0.80         5\n",
            "weighted avg       0.87      0.80      0.80         5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = [\n",
        "    \"secure\",       # clean\n",
        "    \"Ñ•ĞµÑurĞµ\",       # homoglyphs (Cyrillic)\n",
        "    \"password\",     # clean\n",
        "    \"Ñ€Ğ°sswĞ¾rd\",     # homoglyphs\n",
        "]\n",
        "\n",
        "X_new = vectorizer.transform(test_samples)\n",
        "preds = models[\"Logistic Regression\"].predict(X_new)\n",
        "\n",
        "for s, p in zip(test_samples, preds):\n",
        "    print(s, \"->\", \"Homoglyph\" if p == 1 else \"Clean\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz0H4YE0VuFp",
        "outputId": "ebbaf461-cc92-4c8d-c3c0-cdcacca94720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "secure -> Clean\n",
            "Ñ•ĞµÑurĞµ -> Homoglyph\n",
            "password -> Clean\n",
            "Ñ€Ğ°sswĞ¾rd -> Clean\n"
          ]
        }
      ]
    }
  ]
}